{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2cad13-ee2c-4e43-b5c7-31760da8c2df",
   "metadata": {},
   "source": [
    "### Exercise 1.1: A baseline MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports and Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaad5a2713f5ec06"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d96405-36e7-4074-803c-fb02576cd528",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-28T14:58:08.080528900Z",
     "start_time": "2025-08-28T14:58:08.056066500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from dataclasses import dataclass\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "ds_train = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "ds_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "val_size = 5000\n",
    "I = np.random.permutation(len(ds_train))\n",
    "ds_val = Subset(ds_train, I[:val_size])\n",
    "ds_train = Subset(ds_train, I[val_size:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-28T14:58:09.954998700Z",
     "start_time": "2025-08-28T14:58:09.888087600Z"
    }
   },
   "id": "6b9eed240cdc5c43"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-28T14:58:11.257830200Z",
     "start_time": "2025-08-28T14:58:11.231410300Z"
    }
   },
   "id": "cd285d43f958ace5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MLP e Configuration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9af59aaabc8d227d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 1e-3\n",
    "    epochs: int = 10\n",
    "    hidden_layer_sizes: list = None\n",
    "    log_dir: str = \"runs/mnist_mlp_experiment\"\n",
    "    device: torch.device = device\n",
    "    input_size: int = 28*28\n",
    "    num_classes: int = 10\n",
    "    activation_class: type = nn.ReLU   \n",
    "    name: str = None                   \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes, num_classes, activation_class=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layers = [nn.Flatten()]\n",
    "\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(input_size, hidden_layer_size))\n",
    "            layers.append(activation_class())\n",
    "            input_size = hidden_layer_size\n",
    "\n",
    "        layers.append(nn.Linear(input_size, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-28T14:58:15.687681800Z",
     "start_time": "2025-08-28T14:58:15.669453900Z"
    }
   },
   "id": "9785da23c069ba9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training utilities"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a87c4605c2a2994"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, device, epoch=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}\" if epoch is not None else \"Train\", leave=False)\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=running_loss/total_samples, acc=running_corrects/total_samples)\n",
    "\n",
    "    average_loss = running_loss / total_samples\n",
    "    accuracy = running_corrects / total_samples\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, split_name=\"Test\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    loop = tqdm(dataloader, desc=split_name, leave=False)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            loop.set_postfix(loss=running_loss/total_samples, acc=running_corrects/total_samples)\n",
    "\n",
    "    average_loss = running_loss / total_samples\n",
    "    accuracy = running_corrects / total_samples\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def assign_name(config):\n",
    "    config.name = f\"MLP_{'-'.join(map(str, config.hidden_layer_sizes))}\"\n",
    "    return config\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-28T14:58:34.473314700Z",
     "start_time": "2025-08-28T14:58:34.451546700Z"
    }
   },
   "id": "f336c20a68f5eff4"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def run_experiments(configs):\n",
    "    results = []\n",
    "\n",
    "    for config in configs:\n",
    "        config = assign_name(config)\n",
    "        print(f\"\\nRunning experiment: {config.name}\")\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(ds_train, batch_size=config.batch_size, shuffle=True)\n",
    "        test_loader  = torch.utils.data.DataLoader(ds_test, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "        model = MLP(input_size=config.input_size,\n",
    "                    hidden_layer_sizes=config.hidden_layer_sizes,\n",
    "                    num_classes=config.num_classes,\n",
    "                    activation_class=config.activation_class).to(config.device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        writer = SummaryWriter(log_dir=f\"{config.log_dir}/{config.name}\")\n",
    "\n",
    "        best_test_acc = 0.0\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, config.device, epoch)\n",
    "            test_loss, test_acc = evaluate(model, test_loader, criterion, config.device, split_name=\"Test\")\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "            writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "            writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "            writer.add_scalar(\"Accuracy/test\", test_acc, epoch)\n",
    "\n",
    "            if test_acc > best_test_acc:\n",
    "                best_test_acc = test_acc\n",
    "                best_epoch = epoch + 1  \n",
    "\n",
    "        writer.close()\n",
    "\n",
    "        print(f\"Model {config.name} | Best Test Acc: {best_test_acc:.4f} reached at epoch {best_epoch}\")\n",
    "\n",
    "        results.append({\n",
    "            \"model\": config.name,\n",
    "            \"best_test_acc\": best_test_acc,\n",
    "            \"best_epoch\": best_epoch\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"\\nSummary of best test accuracies per model\")\n",
    "    print(df)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-28T14:58:39.350790300Z",
     "start_time": "2025-08-28T14:58:39.328341400Z"
    }
   },
   "id": "d7f892dad600b1fe"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment: MLP_16-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP_16-16 | Best Test Acc: 0.9541 reached at epoch 11\n",
      "\n",
      "Running experiment: MLP_64-32-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP_64-32-16 | Best Test Acc: 0.9712 reached at epoch 11\n",
      "\n",
      "Running experiment: MLP_256-128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP_256-128 | Best Test Acc: 0.9816 reached at epoch 10\n",
      "\n",
      "Summary of best test accuracies per model\n",
      "          model  best_test_acc  best_epoch\n",
      "0     MLP_16-16         0.9541          11\n",
      "1  MLP_64-32-16         0.9712          11\n",
      "2   MLP_256-128         0.9816          10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    Config(hidden_layer_sizes=[16,16], epochs=11),\n",
    "    Config(hidden_layer_sizes=[64,32,16], epochs=11),\n",
    "    Config(hidden_layer_sizes=[256,128], epochs=11),\n",
    "]\n",
    "\n",
    "summary_df = run_experiments(configs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-28T15:10:43.848655300Z",
     "start_time": "2025-08-28T14:58:49.839943800Z"
    }
   },
   "id": "d4a285b3eea52caf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 1.2: Adding Residual Connections\n",
    "\n",
    "Implement a variant of your parameterized MLP network to support **residual** connections. Your network should be defined as a composition of **residual MLP** blocks that have one or more linear layers and add a skip connection from the block input to the output of the final linear layer.\n",
    "\n",
    "**Compare** the performance (in training/validation loss and test accuracy) of your MLP and ResidualMLP for a range of depths. Verify that deeper networks **with** residual connections are easier to train than a network of the same depth **without** residual connections.\n",
    "\n",
    "**For extra style points**: See if you can explain by analyzing the gradient magnitudes on a single training batch *why* this is the case. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "0fb8ad9b-e3ae-4c49-9bec-35aaea149b08"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Your code here."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-28T14:51:36.532711300Z",
     "start_time": "2025-08-28T14:51:36.526095Z"
    }
   },
   "id": "90bcff82-756a-4ffa-92ae-a939fa21f5fd"
  },
  {
   "cell_type": "markdown",
   "id": "3c59bdd8-3377-4311-b45f-511c2fb0b53e",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Rinse and Repeat (but with a CNN)\n",
    "\n",
    "Repeat the verification you did above, but with **Convolutional** Neural Networks. If you were careful about abstracting your model and training code, this should be a simple exercise. Show that **deeper** CNNs *without* residual connections do not always work better and **even deeper** ones *with* residual connections.\n",
    "\n",
    "**Hint**: You probably should do this exercise using CIFAR-10, since MNIST is *very* easy (at least up to about 99% accuracy).\n",
    "\n",
    "**Tip**: Feel free to reuse the ResNet building blocks defined in `torchvision.models.resnet` (e.g. [BasicBlock](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L59) which handles the cascade of 3x3 convolutions, skip connections, and optional downsampling). This is an excellent exercise in code diving. \n",
    "\n",
    "**Spoiler**: Depending on the optional exercises you plan to do below, you should think *very* carefully about the architectures of your CNNs here (so you can reuse them!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c8baa0e-b17f-4a77-8a88-dadfdc6763ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:51:36.577276600Z",
     "start_time": "2025-08-28T14:51:36.528621500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4de2f2-abc5-4f98-9eaf-3497f734a022",
   "metadata": {},
   "source": [
    "-----\n",
    "## Exercise 2: Choose at Least One\n",
    "\n",
    "Below are **three** exercises that ask you to deepen your understanding of Deep Networks for visual recognition. You must choose **at least one** of the below for your final submission -- feel free to do **more**, but at least **ONE** you must submit. Each exercise is designed to require you to dig your hands **deep** into the guts of your models in order to do new and interesting things.\n",
    "\n",
    "**Note**: These exercises are designed to use your small, custom CNNs and small datasets. This is to keep training times reasonable. If you have a decent GPU, feel free to use pretrained ResNets and larger datasets (e.g. the [Imagenette](https://pytorch.org/vision/0.20/generated/torchvision.datasets.Imagenette.html#torchvision.datasets.Imagenette) dataset at 160px)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07978e8e-9f2e-4949-9699-495af6cb6349",
   "metadata": {},
   "source": [
    "### Exercise 2.1: *Fine-tune* a pre-trained model\n",
    "Train one of your residual CNN models from Exercise 1.3 on CIFAR-10. Then:\n",
    "1. Use the pre-trained model as a **feature extractor** (i.e. to extract the feature activations of the layer input into the classifier) on CIFAR-100. Use a **classical** approach (e.g. Linear SVM, K-Nearest Neighbor, or Bayesian Generative Classifier) from scikit-learn to establish a **stable baseline** performance on CIFAR-100 using the features extracted using your CNN.\n",
    "2. Fine-tune your CNN on the CIFAR-100 training set and compare with your stable baseline. Experiment with different strategies:\n",
    "    - Unfreeze some of the earlier layers for fine-tuning.\n",
    "    - Test different optimizers (Adam, SGD, etc.).\n",
    "\n",
    "Each of these steps will require you to modify your model definition in some way. For 1, you will need to return the activations of the last fully-connected layer (or the global average pooling layer). For 2, you will need to replace the original, 10-class classifier with a new, randomly-initialized 100-class classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469e81a3-08ca-4549-a2f8-f47cf5a0308b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-28T14:51:36.588675600Z",
     "start_time": "2025-08-28T14:51:36.534749100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a3a7b-2ed6-4f58-a1b7-5ab1fc432893",
   "metadata": {},
   "source": [
    "### Exercise 2.2: *Distill* the knowledge from a large model into a smaller one\n",
    "In this exercise you will see if you can derive a *small* model that performs comparably to a larger one on CIFAR-10. To do this, you will use [Knowledge Distillation](https://arxiv.org/abs/1503.02531):\n",
    "\n",
    "> Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the Knowledge in a Neural Network, NeurIPS 2015.\n",
    "\n",
    "To do this:\n",
    "1. Train one of your best-performing CNNs on CIFAR-10 from Exercise 1.3 above. This will be your **teacher** model.\n",
    "2. Define a *smaller* variant with about half the number of parameters (change the width and/or depth of the network). Train it on CIFAR-10 and verify that it performs *worse* than your **teacher**. This small network will be your **student** model.\n",
    "3. Train the **student** using a combination of **hard labels** from the CIFAR-10 training set (cross entropy loss) and **soft labels** from predictions of the **teacher** (Kulback-Leibler loss between teacher and student).\n",
    "\n",
    "Try to optimize training parameters in order to maximize the performance of the student. It should at least outperform the student trained only on hard labels in Setp 2.\n",
    "\n",
    "**Tip**: You can save the predictions of the trained teacher network on the training set and adapt your dataloader to provide them together with hard labels. This will **greatly** speed up training compared to performing a forward pass through the teacher for each batch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e33c912-0716-44ef-a91b-47ca19a2b2cd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-28T14:51:36.589687300Z",
     "start_time": "2025-08-28T14:51:36.543936800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243f811-8227-4c6f-b07f-56e8cd91643a",
   "metadata": {},
   "source": [
    "### Exercise 2.3: *Explain* the predictions of a CNN\n",
    "\n",
    "Use the CNN model you trained in Exercise 1.3 and implement [*Class Activation Maps*](http://cnnlocalization.csail.mit.edu/#:~:text=A%20class%20activation%20map%20for,decision%20made%20by%20the%20CNN.):\n",
    "\n",
    "> B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization. CVPR'16 (arXiv:1512.04150, 2015).\n",
    "\n",
    "Use your CNN implementation to demonstrate how your trained CNN *attends* to specific image features to recognize *specific* classes. Try your implementation out using a pre-trained ResNet-18 model and some images from the [Imagenette](https://pytorch.org/vision/0.20/generated/torchvision.datasets.Imagenette.html#torchvision.datasets.Imagenette) dataset -- I suggest you start with the low resolution version of images at 160px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d634a700-56c2-48fd-96e0-4c94d1bd0cfe",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-28T14:51:36.589687300Z",
     "start_time": "2025-08-28T14:51:36.549897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
